{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.jupyter.org/github/alexander-de-leeuw/innoplexus-online-hackathon/blob/master/Innoplexus%20-%20online%20hackathon.ipynb?flush_cache=true\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/CoilData.csv')\n",
    "coils = pd.read_csv('../data/output.csv')\n",
    "coil_list = list(map(int,list(coils.columns)))\n",
    "lst = []\n",
    "for i in df['coil']:\n",
    "    if i in coil_list:\n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "df['contracted'] = lst\n",
    "df['analyse_main'] = [i[0:3] for i in df['analyse']]\n",
    "dummies_analyse_main = pd.get_dummies(df['analyse_main'], dtype=float)\n",
    "df = df.drop(columns=['coil', 'analyse', 'analyse_main'])\n",
    "data = df\n",
    "# data = df.join(dummies_analyse_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Thickness profile'] = data['Thickness profile'].apply(lambda x: x.replace('*******', ''))\n",
    "data = data.replace('', np.nan, regex=True).dropna().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection and partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         0         1         2        3  \\\n",
      "furnace Number                        1.00      1.00      4.00      1.0   \n",
      "Hardness_1                         9771.00  12833.00  12406.00  11963.0   \n",
      "Hardness_2                           98.00    134.00    129.00    106.0   \n",
      "Width                               943.50    807.40   1497.90    913.2   \n",
      "Temperature before finishing mill  1149.00   1180.00   1154.00   1154.0   \n",
      "Temperature after finishing mill    936.00    863.00    906.00    952.0   \n",
      "Thickness                             3.78      3.02      3.82      2.8   \n",
      "Thickness profile                    17.00     28.00     40.00     28.0   \n",
      "c                                   356.00    665.00    676.00     18.0   \n",
      "mn                                 2034.00  14040.00   8772.00   7009.0   \n",
      "si                                  125.00   1328.00    133.00    699.0   \n",
      "nb                                    0.00    249.00    431.00     32.0   \n",
      "p                                    59.00    153.00    143.00    713.0   \n",
      "s                                    58.00     20.00     35.00     77.0   \n",
      "al                                  314.00    392.00    400.00    473.0   \n",
      "ma                                  297.00    383.00    387.00    462.0   \n",
      "b                                     1.00      3.00      1.00      5.0   \n",
      "n                                    27.00     38.00     31.00     16.0   \n",
      "ti                                   14.00     26.00    257.00    123.0   \n",
      "cr                                  285.00    309.00    193.00    329.0   \n",
      "va                                   13.00      6.00      0.00      0.0   \n",
      "mo                                   11.00     20.00     22.00     47.0   \n",
      "contracted                            0.00      1.00      0.00      1.0   \n",
      "\n",
      "                                          4  \n",
      "furnace Number                         3.00  \n",
      "Hardness_1                         10040.00  \n",
      "Hardness_2                           100.00  \n",
      "Width                               1293.30  \n",
      "Temperature before finishing mill   1184.00  \n",
      "Temperature after finishing mill     907.00  \n",
      "Thickness                              6.26  \n",
      "Thickness profile                      0.00  \n",
      "c                                    412.00  \n",
      "mn                                  1984.00  \n",
      "si                                   133.00  \n",
      "nb                                     1.00  \n",
      "p                                    121.00  \n",
      "s                                     76.00  \n",
      "al                                   428.00  \n",
      "ma                                   378.00  \n",
      "b                                      1.00  \n",
      "n                                     26.00  \n",
      "ti                                     2.00  \n",
      "cr                                   262.00  \n",
      "va                                     2.00  \n",
      "mo                                    25.00  \n",
      "contracted                             0.00  \n"
     ]
    }
   ],
   "source": [
    "# Making balanced datasets\n",
    "len_coil_list = len(coil_list)\n",
    "df_good_coils = data[data.contracted == 0].sample(len_coil_list)\n",
    "df_bad_coils = data[data.contracted == 1]\n",
    "\n",
    "# concat even number of good and bad coils in df and reshuffle the dataframe so we randomize the the data when we\n",
    "# split it. \n",
    "df_balanced_coils = pd.concat([df_good_coils, df_bad_coils]).sample(frac=1).reset_index(drop=True)\n",
    "print(df_balanced_coils.head().T)\n",
    "\n",
    "X = df_balanced_coils.iloc[:,:-1]\n",
    "y = df_balanced_coils.contracted\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('decsT', DecisionTreeClassifier())])\n",
    "\n",
    "pipe_rf = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', svm.SVC(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "param_range = [9, 10]\n",
    "param_range_fl = [1.0, 0.5]\n",
    "max_depth_range = np.arange(3,15)\n",
    "min_samples_leaf_range = ...\n",
    "\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': param_range_fl,\n",
    "        'clf__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_dt = [{'decsT__max_depth': ['gini', 'entropy'],\n",
    "                  'decsT__max_depth': max_depth_range}]\n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range}]\n",
    "\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
    "        'clf__C': param_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = GridSearchCV(estimator=pipe_lr,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10)\n",
    "\n",
    "DT = GridSearchCV(estimator=pipe_dt,\n",
    "                 param_grid=grid_params_dt,\n",
    "                 scoring='accuracy')\n",
    "\n",
    "RF = GridSearchCV(estimator=pipe_rf,\n",
    "                 param_grid=grid_params_rf,\n",
    "                 scoring='accuracy',\n",
    "                 cv=10)\n",
    "\n",
    "SVM = GridSearchCV(estimator=pipe_svm,\n",
    "                  param_grid=grid_params_svm,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [LR, DT, RF, SVM]\n",
    "\n",
    "# Creating a dict for our reference\n",
    "grid_dict = {0: 'Logistic Regression',\n",
    "            1: 'Decision Tree Classifier',\n",
    "            2: 'Random Forest Classifier',\n",
    "            3: 'Support Vector Machine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params are : {'clf__C': 0.5, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.784\n",
      "Test set accuracy score for best params: 0.763 \n",
      "\n",
      "Estimator: Decision Tree Classifier\n",
      "Best params are : {'decsT__max_depth': 9}\n",
      "Best training accuracy: 0.795\n",
      "Test set accuracy score for best params: 0.783 \n",
      "\n",
      "Estimator: Random Forest Classifier\n",
      "Best params are : {'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_split': 10}\n",
      "Best training accuracy: 0.830\n",
      "Test set accuracy score for best params: 0.806 \n",
      "\n",
      "Estimator: Support Vector Machine\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    gs.fit(x_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(x_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_grid_search_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Train model\n",
    "# pipe = Pipeline(['scaler', StandardScaler(),\n",
    "#        'clf', LogisticRegression()])\n",
    "\n",
    "# pipe.fit(x_train, y_train)\n",
    "# print(pipe.score(x_test, y_test))\n",
    "\n",
    "# # Make predictions\n",
    "# y_train_pred_proba = pipe.predict_proba(x_train)[:,1]\n",
    "# y_test_pred_proba = pipe.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Observe general model performance\n",
    "# print('train roc auc: {:.2f}'.format(roc_auc_score(y_train, y_train_pred_proba)))\n",
    "# print('test roc auc:   {:.2f}'.format(roc_auc_score(y_test, y_test_pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Observe general model performance\n",
    "# y_train_pred = y_train_pred_proba > 0.5\n",
    "# y_test_pred = y_test_pred_proba > 0.5\n",
    "\n",
    "# print('train f1:      {:.2f}'.format(f1_score(y_train, y_train_pred)))\n",
    "# print('test f1:        {:.2f}'.format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
