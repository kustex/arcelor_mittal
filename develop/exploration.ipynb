{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/CoilData.csv')\n",
    "coils = pd.read_csv('../data/output.csv')\n",
    "coil_list = list(map(int,list(coils.columns)))\n",
    "lst = []\n",
    "for i in df['coil']:\n",
    "    if i in coil_list:\n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "df['contracted'] = lst\n",
    "df['analyse_main'] = [i[0:4] for i in df['analyse']]\n",
    "dummies_analyse_main = pd.get_dummies(df['analyse_main'], dtype=float)\n",
    "df = df.drop(columns=['coil', 'analyse', 'analyse_main', 'furnace Number', 'Temperature before finishing mill', 'Temperature after finishing mill'])\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# replace string values in Thickness profile column\n",
    "data['Thickness profile'] = data['Thickness profile'].apply(lambda x: x.replace('*******', ''))\n",
    "data = data.replace('', np.nan, regex=True).dropna().astype(float)\n",
    "data = data[data['Thickness profile'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check negative values in Thickness profile\n",
    "# neg_val_thick_profile = len(data['Thickness profile'][data['Thickness profile'] < 0])\n",
    "# print(neg_val_thick_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hardness_1 Hardness_2     Width Thickness Thickness profile\n",
      "0  -0.864475  -0.593122  0.143819  0.748022          0.910067\n",
      "1  -0.775493  -0.593122  0.075519  0.757278          1.273254\n",
      "2  -0.837039  -0.533462  0.127606  0.812812          0.365286\n",
      "3  -0.686510  -0.533462  0.120018  0.822067          0.637677\n",
      "4  -0.857802  -0.652781  0.113463  0.368543          0.456083\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "selection_standardize = data.iloc[:,0:5]\n",
    "list_columns = selection_standardize.columns\n",
    "scaled_selection = pd.DataFrame(data=scaler.fit_transform(selection_standardize), columns=[list_columns])\n",
    "print(scaled_selection.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform to log data and replace -inf values with min value != 0 \n",
    "# in each column and get the log of that number divided by 1000\n",
    "log_selection = data.iloc[:,5:19]\n",
    "for column in list(log_selection.columns):\n",
    "    min_value_per_column = min(i for i in log_selection.loc[:,column] if i > 0)\n",
    "    log_selection.loc[:,column] = np.log(log_selection.loc[:,column]).replace(-np.inf, np.log(min_value_per_column/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            c        mn        si        nb         p         s        al  \\\n",
      "513  0.107368  0.779721  0.635883  0.176186  0.631191  0.364448  0.590557   \n",
      "605  0.670636  0.821765  0.735643 -0.311839  0.542217  0.019588  0.568902   \n",
      "606  0.664946  0.820326  0.732402 -1.118914  0.532236  0.145198  0.573764   \n",
      "607  0.664946  0.820326  0.732402 -1.118914  0.532236  0.145198  0.573764   \n",
      "608  0.650477  0.827498  0.721197 -0.133998  0.491695  0.244001  0.566924   \n",
      "\n",
      "           ma         b         n  ...  TB31  TB32  TB41  TB43  TB51  TB53  \\\n",
      "513  0.586263 -0.539228  0.133470  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "605  0.564894 -2.363952  0.281215  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "606  0.570284 -1.118914  0.244001  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "607  0.570284 -1.118914  0.244001  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "608  0.563110 -2.363952  0.310462  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "     TB61  TB63  TB71  contracted  \n",
      "513   0.0   0.0   0.0           0  \n",
      "605   0.0   0.0   0.0           0  \n",
      "606   0.0   0.0   0.0           0  \n",
      "607   0.0   0.0   0.0           0  \n",
      "608   0.0   0.0   0.0           0  \n",
      "\n",
      "[5 rows x 242 columns]\n"
     ]
    }
   ],
   "source": [
    "# Join dataframes and adding OneHotEncoding for Categorical values of 'Analyse' column\n",
    "data = log_selection.join(scaled_selection).join(dummies_analyse_main).join(df['contracted']).dropna()\n",
    "# data = log_selection.join(dummies_analyse_main).join(df['contracted']).dropna()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection and partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Making balanced datasets\n",
    "len_coil_list = len(coil_list)\n",
    "df_good_coils = data[data.contracted == 0].sample(len_coil_list)\n",
    "df_bad_coils = data[data.contracted == 1]\n",
    "\n",
    "# concat even number of good and bad coils in df and reshuffle the dataframe so we randomize the the data when we\n",
    "# split it. \n",
    "df_balanced_coils = pd.concat([df_good_coils, df_bad_coils]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = df_balanced_coils.iloc[:,:-1]\n",
    "y = df_balanced_coils.contracted\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "svm = svm.SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "max_depth_range = np.arange(3,15,3)\n",
    "max_iter = np.arange(100,1000,100)\n",
    "\n",
    "grid_params_lr = [{'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "                  'max_iter': [1000,2000,3000]}]\n",
    "\n",
    "grid_params_dt = [{'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': max_depth_range}]\n",
    "\n",
    "grid_params_rf = [{'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': max_depth_range,\n",
    "        'min_samples_split': max_depth_range}]\n",
    "\n",
    "grid_params_svm = [{'kernel': ['linear', 'rbf'], \n",
    "        'C': max_depth_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = GridSearchCV(lr,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=3)\n",
    "\n",
    "DT = GridSearchCV(dt,\n",
    "                 param_grid=grid_params_dt,\n",
    "                 scoring='accuracy',\n",
    "                 cv=3)\n",
    "\n",
    "RF = GridSearchCV(rf,\n",
    "                 param_grid=grid_params_rf,\n",
    "                 scoring='accuracy',\n",
    "                 cv=3)\n",
    "\n",
    "SVM = GridSearchCV(svm,\n",
    "                  param_grid=grid_params_svm,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [LR, DT, RF, SVM]\n",
    "\n",
    "# Creating a dict for our reference\n",
    "grid_dict = {0: 'Logistic Regression',\n",
    "            1: 'Decision Tree Classifier',\n",
    "            2: 'Random Forest Classifier',\n",
    "            3: 'Support Vector Machine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params are : {'max_iter': 1000, 'multi_class': 'multinomial'}\n",
      "Best training accuracy: 0.902\n",
      "Test set accuracy score for best params: 0.907 \n",
      "\n",
      "Estimator: Decision Tree Classifier\n",
      "Best params are : {'criterion': 'gini', 'max_depth': 3}\n",
      "Best training accuracy: 0.902\n",
      "Test set accuracy score for best params: 0.910 \n",
      "\n",
      "Estimator: Random Forest Classifier\n",
      "Best params are : {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 6}\n",
      "Best training accuracy: 0.906\n",
      "Test set accuracy score for best params: 0.912 \n",
      "\n",
      "Estimator: Support Vector Machine\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    gs.fit(x_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(x_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_grid_search_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of GridSearchCV parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
